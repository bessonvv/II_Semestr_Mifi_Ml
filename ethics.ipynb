{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eea92d51",
   "metadata": {},
   "source": [
    "# **Задача**\n",
    "\n",
    "В конце 2017 года платформа Civil Comments закрылась и опубликовала около 2 миллионов комментариев из социальных сетей, чтобы специалисты по данным со всего мира могли работать вместе над исследованием способов смягчения предвзятости в текстовых данных.\n",
    "\n",
    "Таблица с комментариями также прилагается: data.csv. Мы будем работать с тысячами комментариев, где каждый комментарий помечен как «токсичный» или «нетоксичный».\n",
    "\n",
    "В таблице data.csv в колонке comment_text написаны сами комментарии, с которыми нам предстоит работать. В колонке target стоят вероятности того, что комментарий токсичен. Давайте сделаем предпосылку, что комментарий считается токсичным, если вероятность выше 0.7.\n",
    "\n",
    "Выполняем код ниже, чтобы отделить колонки и преобразовать вероятности в бинарные величины, где 1 — токсичный комментарий, а 0 — нетоксичный комментарий."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc51791e-dbc7-4aa1-88eb-c1e047170d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Get the same results each time\n",
    "np.random.seed(0)\n",
    "\n",
    "\n",
    "# Load the training data\n",
    "data = pd.read_csv(\"D:/mifi/myvenv/ML_ethic/data.csv\")\n",
    "comments = data[\"comment_text\"]\n",
    "target = (data[\"target\"]>0.7).astype(int) # Преобразуем вероятности в бинарные метки: 1, если target > 0.7, иначе 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c12f271",
   "metadata": {},
   "source": [
    "### **Исследование датасетов**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f2f8e9cc-9791-4a68-b3c8-0cfb9fa8056a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "target",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "comment_text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "severe_toxicity",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "obscene",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "identity_attack",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "insult",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "threat",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "asian",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "atheist",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "bisexual",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "black",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "buddhist",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "christian",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "female",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "heterosexual",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "hindu",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "homosexual_gay_or_lesbian",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "intellectual_or_learning_disability",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "jewish",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "latino",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "male",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "muslim",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "other_disability",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "other_gender",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "other_race_or_ethnicity",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "other_religion",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "other_sexual_orientation",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "physical_disability",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "psychiatric_or_mental_illness",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "transgender",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "white",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "created_date",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "publication_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "parent_id",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "article_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "rating",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "funny",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "wow",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "sad",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "likes",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "disagree",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "sexual_explicit",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "identity_annotator_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "toxicity_annotator_count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "05aa99fd-fe96-48ac-b4fc-feb426ba2ef8",
       "rows": [
        [
         "2",
         "239612",
         "0.8307692307692307",
         "This bitch is nuts. Who would read a book by a woman.",
         "0.1076923076923077",
         "0.6615384615384615",
         "0.3384615384615385",
         "0.8307692307692307",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "2016-01-13 21:08:08.861688+00",
         "6",
         null,
         "26674",
         "rejected",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0.0615384615384615",
         "4",
         "65"
        ],
        [
         "5",
         "240400",
         "0.8333333333333333",
         "Nincompoop, that's a nice one! I'm partial to silly goose.",
         "0.0",
         "0.0",
         "0.0",
         "0.8333333333333333",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "2015-09-29 18:21:30.915678+00",
         "111",
         "240399.0",
         "32846",
         "approved",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0.0",
         "4",
         "6"
        ],
        [
         "11",
         "240879",
         "0.7777777777777779",
         "\"Real freedom\"? Freedom to kill wantonly when YOU decide you're in the right? This is why we have laws; both Federal and State; to control the likes of these assholes. They should all be rounded up and imprisoned, all their property taken away to be sold to pay for this travesty they call an, \"occupation\". Pure scum, not patriots.",
         "0.0493827160493827",
         "0.2839506172839506",
         "0.0246913580246913",
         "0.7530864197530864",
         "0.1111111111111111",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "2016-01-25 17:36:00.756591+00",
         "6",
         "240865.0",
         "33626",
         "approved",
         "0",
         "0",
         "0",
         "3",
         "0",
         "0.0617283950617283",
         "4",
         "81"
        ],
        [
         "23",
         "242779",
         "0.7285714285714285",
         "Wow, you wouldn't know a FACT, about the Bundys, if it bit you in the ass! Terrorist??? Only a typical backward thinking big-government loving liberal, force fits/bastardizes words to fit their whore-mongering agendas.",
         "0.0714285714285714",
         "0.6571428571428571",
         "0.0571428571428571",
         "0.5714285714285714",
         "0.0428571428571428",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "2016-02-11 08:51:02.747625+00",
         "6",
         "242777.0",
         "37903",
         "rejected",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0.5857142857142859",
         "4",
         "70"
        ],
        [
         "25",
         "243373",
         "0.85",
         "Notwithstanding the fact the protester is an idiot, that 1st Cav patch is known as 'the horse blanket' for it's size.",
         "0.0166666666666666",
         "0.2666666666666666",
         "0.0166666666666666",
         "0.85",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "2016-02-11 21:51:49.502348+00",
         "6",
         "243354.0",
         "38031",
         "approved",
         "0",
         "0",
         "0",
         "3",
         "0",
         "0.0",
         "4",
         "60"
        ]
       ],
       "shape": {
        "columns": 45,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>severe_toxicity</th>\n",
       "      <th>obscene</th>\n",
       "      <th>identity_attack</th>\n",
       "      <th>insult</th>\n",
       "      <th>threat</th>\n",
       "      <th>asian</th>\n",
       "      <th>atheist</th>\n",
       "      <th>...</th>\n",
       "      <th>article_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>funny</th>\n",
       "      <th>wow</th>\n",
       "      <th>sad</th>\n",
       "      <th>likes</th>\n",
       "      <th>disagree</th>\n",
       "      <th>sexual_explicit</th>\n",
       "      <th>identity_annotator_count</th>\n",
       "      <th>toxicity_annotator_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>239612</td>\n",
       "      <td>0.830769</td>\n",
       "      <td>This bitch is nuts. Who would read a book by a...</td>\n",
       "      <td>0.107692</td>\n",
       "      <td>0.661538</td>\n",
       "      <td>0.338462</td>\n",
       "      <td>0.830769</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>26674</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.061538</td>\n",
       "      <td>4</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>240400</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>Nincompoop, that's a nice one! I'm partial to ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>32846</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>240879</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>\"Real freedom\"? Freedom to kill wantonly when ...</td>\n",
       "      <td>0.049383</td>\n",
       "      <td>0.283951</td>\n",
       "      <td>0.024691</td>\n",
       "      <td>0.753086</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>33626</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.061728</td>\n",
       "      <td>4</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>242779</td>\n",
       "      <td>0.728571</td>\n",
       "      <td>Wow, you wouldn't know a FACT, about the Bundy...</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.657143</td>\n",
       "      <td>0.057143</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.042857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>37903</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.585714</td>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>243373</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>Notwithstanding the fact the protester is an i...</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>38031</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id    target                                       comment_text  \\\n",
       "2   239612  0.830769  This bitch is nuts. Who would read a book by a...   \n",
       "5   240400  0.833333  Nincompoop, that's a nice one! I'm partial to ...   \n",
       "11  240879  0.777778  \"Real freedom\"? Freedom to kill wantonly when ...   \n",
       "23  242779  0.728571  Wow, you wouldn't know a FACT, about the Bundy...   \n",
       "25  243373  0.850000  Notwithstanding the fact the protester is an i...   \n",
       "\n",
       "    severe_toxicity   obscene  identity_attack    insult    threat  asian  \\\n",
       "2          0.107692  0.661538         0.338462  0.830769  0.000000    0.0   \n",
       "5          0.000000  0.000000         0.000000  0.833333  0.000000    0.0   \n",
       "11         0.049383  0.283951         0.024691  0.753086  0.111111    0.0   \n",
       "23         0.071429  0.657143         0.057143  0.571429  0.042857    0.0   \n",
       "25         0.016667  0.266667         0.016667  0.850000  0.000000    0.0   \n",
       "\n",
       "    atheist  ...  article_id    rating  funny  wow  sad  likes  disagree  \\\n",
       "2       0.0  ...       26674  rejected      0    0    0      0         0   \n",
       "5       0.0  ...       32846  approved      0    0    0      0         0   \n",
       "11      0.0  ...       33626  approved      0    0    0      3         0   \n",
       "23      0.0  ...       37903  rejected      0    0    0      0         0   \n",
       "25      0.0  ...       38031  approved      0    0    0      3         0   \n",
       "\n",
       "    sexual_explicit  identity_annotator_count  toxicity_annotator_count  \n",
       "2          0.061538                         4                        65  \n",
       "5          0.000000                         4                         6  \n",
       "11         0.061728                         4                        81  \n",
       "23         0.585714                         4                        70  \n",
       "25         0.000000                         4                        60  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "8bc84fba-7af4-4ff8-a0d2-b9933dfee954",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "target",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "ae72fbd0-f7db-4ddf-97c7-dcc3c2aa29ed",
       "rows": [
        [
         "2",
         "1"
        ],
        [
         "5",
         "1"
        ],
        [
         "11",
         "1"
        ],
        [
         "23",
         "1"
        ],
        [
         "25",
         "1"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 5
       }
      },
      "text/plain": [
       "2     1\n",
       "5     1\n",
       "11    1\n",
       "23    1\n",
       "25    1\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0623f3e",
   "metadata": {},
   "source": [
    "# **Задание 1**\n",
    "Теперь разделим наши данные на train и test. Пусть в тест у нас пойдет 30% данных. Для этого можете использовать библиотеку train_test_split из sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "72b5fc48-5cd5-428b-8296-4dc250a349da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер тренировочного датасета: 7275\n",
      "<class 'pandas.core.series.Series'>\n",
      "Index: 7275 entries, 69855 to 22996\n",
      "Series name: comment_text\n",
      "Non-Null Count  Dtype \n",
      "--------------  ----- \n",
      "7275 non-null   object\n",
      "dtypes: object(1)\n",
      "memory usage: 113.7+ KB\n"
     ]
    }
   ],
   "source": [
    "comm_train, comm_test, target_train, target_test = train_test_split(\n",
    "    comments, target, test_size=0.3, random_state=0\n",
    ")\n",
    "\n",
    "# Инорфмация о тренировочном наборе\n",
    "print(\"Размер тренировочного датасета:\", len(comm_train))\n",
    "comm_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db24b65",
   "metadata": {},
   "source": [
    "# **Задание 2**\n",
    "\n",
    "Как вы уже, наверное, догадались, в наших данных есть определенная проблема — это разные типы данных. Предсказывать мы хотим бинарную величину: 1 и 0. А на вход мы подаем текст, а не числа. Поэтому нам нужно как-то сконвертировать текст в число."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "39da031a-feef-4501-9c09-83ee488a6f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размерность обучающей выборки после векторизации: (7275, 20120)\n",
      "Размерность тестовой выборки после векторизации: (3118, 20120)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Обучаем векторизатор и преобразуем\n",
    "comments_train_vec = vectorizer.fit_transform(comm_train)\n",
    "\n",
    "# Применяем обученный векторизатор \n",
    "comments_test_vec = vectorizer.transform(comm_test)\n",
    "\n",
    "print(f\"Размерность обучающей выборки после векторизации: {comments_train_vec.shape}\")\n",
    "print(f\"Размерность тестовой выборки после векторизации: {comments_test_vec.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51beaee",
   "metadata": {},
   "source": [
    "# **Задание 3**\n",
    "Теперь в качестве модели, которая будет классифицировать нам комментарии на токсичные и нетоксичные, возьмем логистическую регрессию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "8359f8d0-f56d-4413-8ddc-837b56aec2e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy test: 0.8855\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(max_iter=2000)\n",
    "model.fit(comments_train_vec, target_train)\n",
    "\n",
    "# предсказания на тестовой выборке\n",
    "predictions = model.predict(comments_test_vec)\n",
    "\n",
    "# Сaccuracy\n",
    "accuracy = accuracy_score(target_test, predictions)\n",
    "\n",
    "print(f\"Accuracy test: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb0f72c",
   "metadata": {},
   "source": [
    "# **Задание 4**\n",
    "\n",
    "Чтобы мы смогли протестировать разные комментарии, которые приходят в голову, пропишите ниже функцию, для которой на вход мы бы подавали наш комментарий, а на выход получали предсказание, насколько от 0 до 1 комментарий является токсичным."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "32d9921b-9d54-4dd2-b0eb-b4cf46d5ffd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.959609421904435\n",
      "0.1993496680447563\n"
     ]
    }
   ],
   "source": [
    "# Функция для предсказания токсичности нового комментария\n",
    "def predict_toxicity(comment: str) -> float:\n",
    "    # Предсказывает вероятность того, что комментарий является токсичным.\n",
    "    # Входной комментарий -строка\n",
    "    # Вероятность токсичности - число от 0 до 1 (1-высшая токсичность)\n",
    "\n",
    "    # Преобразуем входной комментарий с использованием того же обученного векторизатора\n",
    "    comment_vec = vectorizer.transform([comment])\n",
    "\n",
    "    # Получаем вероятности для каждого класса (0 и 1)\n",
    "    probabilities = model.predict_proba(comment_vec)\n",
    "\n",
    "    # Возвращаем вероятность для класса 1 (токсичный комментарий)\n",
    "    return probabilities[0][1]\n",
    "\n",
    "# для примера:\n",
    "print(predict_toxicity(\"How are you doing, I think it's going crazy shit?\"))\n",
    "print(predict_toxicity(\"Good day, are you shure it's ok?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1b5692",
   "metadata": {},
   "source": [
    "Предсказания совпадают с ожиданиями"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd74ba9",
   "metadata": {},
   "source": [
    "# Задание 5\n",
    "\n",
    "Поздравляю! Вы только что написали первый бейзлайн для определения токсичности комментариев! :)\n",
    "\n",
    "А теперь посмотрим, насколько он этичен.\n",
    "\n",
    "Попробуйте предсказать, токсичен ли комментарий «Apples are stupid». Потом предскажите, токсичен ли комментарий «I love apples»."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "70d2bd91-97ea-4368-be70-f663935d8c9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9941491240407159\n",
      "0.2533215111840326\n"
     ]
    }
   ],
   "source": [
    "comment1 = \"Apples are stupid\"\n",
    "comment2 = \"I love apples\"\n",
    "\n",
    "print(predict_toxicity(comment1))\n",
    "print(predict_toxicity(comment2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f9e09b",
   "metadata": {},
   "source": [
    "Предсказания снова совпали с ожиданием"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e4846f",
   "metadata": {},
   "source": [
    "# Задание 6\n",
    "\n",
    "Если ваш алгоритм работает корректно, то комментарий «I love apples» должен быть определен как нетоксичный, а «Apples are stupid» — как токсичный.\n",
    "\n",
    "А теперь перейдем к пониманию того, как модель принимает решения: модель присваивает каждому из примерно 58 000 слов коэффициент, причем более высокие коэффициенты обозначают слова, которые модель считает более токсичными. Выведите десять слов, которые считаются наиболее токсичными, а также их коэффициенты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "98a90b46-0f92-40cc-a9c3-cd92f23074d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Слово: 'stupid' | Коэффициент: 5.9167\n",
      "Слово: 'idiot' | Коэффициент: 4.9859\n",
      "Слово: 'idiots' | Коэффициент: 4.4323\n",
      "Слово: 'stupidity' | Коэффициент: 3.8801\n",
      "Слово: 'dumb' | Коэффициент: 3.7934\n",
      "Слово: 'pathetic' | Коэффициент: 3.6465\n",
      "Слово: 'crap' | Коэффициент: 3.6392\n",
      "Слово: 'ignorant' | Коэффициент: 3.5086\n",
      "Слово: 'bitch' | Коэффициент: 3.4354\n",
      "Слово: 'moron' | Коэффициент: 3.3648\n",
      "Слово: 'damn' | Коэффициент: 3.3618\n",
      "Слово: 'ridiculous' | Коэффициент: 3.2302\n",
      "Слово: 'ass' | Коэффициент: 3.1135\n",
      "Слово: 'garbage' | Коэффициент: 3.1027\n",
      "Слово: 'idiotic' | Коэффициент: 3.0650\n",
      "Слово: 'hypocrite' | Коэффициент: 2.9520\n",
      "Слово: 'loser' | Коэффициент: 2.9430\n",
      "Слово: 'fool' | Коэффициент: 2.8547\n",
      "Слово: 'morons' | Коэффициент: 2.8435\n",
      "Слово: 'silly' | Коэффициент: 2.7878\n"
     ]
    }
   ],
   "source": [
    "# Вывод десяти слов с наибольшими коэффициентами (считающихся наиболее токсичными)\n",
    "\n",
    "# Получаем коэффициенты \n",
    "word_coefficients = model.coef_[0]\n",
    "\n",
    "# Создадим обратный словарь: индекс -> слово\n",
    "index_to_word = {index: word for word, index in vectorizer.vocabulary_.items()}\n",
    "\n",
    "# Сопоставляем коэффициенты словам, используя обратный словарь\n",
    "word_to_coeff= {\n",
    "    index_to_word[i]: word_coefficients[i]\n",
    "    for i in range(len(word_coefficients)) # Проходим по всем индексам коэффициентов\n",
    "}\n",
    "\n",
    "# Сортируем слова по убыванию коэффициентов из альтернативного словаря и берем топ-10\n",
    "most_toxic_words = sorted(word_to_coeff.items(), key=lambda item: item[1], reverse=True)[:20]\n",
    "\n",
    "for word, coeff in most_toxic_words:\n",
    "    print(f\"Слово: '{word}' | Коэффициент: {coeff:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5906436a-8199-42dd-a5cc-f4ba771519d6",
   "metadata": {},
   "source": [
    "# Задание 7\n",
    "Взгляните на самые токсичные слова из задания 6. Вызывают ли у вас удивление какие-нибудь из них? Есть ли слова, которых, кажется, не должно быть в списке?\n",
    "\n",
    "Присутствуют слова токсичные,  но некоторые надо рассматривать в  контексте:\n",
    "- pathetic - жалкий\n",
    "- hypocrite - лицимер\n",
    "- ignorant - невежественный"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d711a7e8-c24f-4a86-bc28-fb78287bf0ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.85908329173186\n",
      "0.9570992347746421\n"
     ]
    }
   ],
   "source": [
    "pathetic = \"His pathetic attempt to win the argument only made the situation more embarrassing.\" #Бил лицимер, потомучто скрывает правду\n",
    "hypocrite = \"She accused him of being a hypocrite after he criticized her for something he himself had done.\" #Ему постоянно говорили, что он невежественный\n",
    "\n",
    "print(predict_toxicity(pathetic))\n",
    "print(predict_toxicity(hypocrite))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c71608",
   "metadata": {},
   "source": [
    "# Задание 8\n",
    "\n",
    "Давайте попробуем протестировать модель на ее предвзятость, например, к религии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "d08c9017-fdb9-4612-974b-cff8bb4600cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4151673080399158\n",
      "0.42155025913898503\n",
      "0.3617148193271017\n",
      "0.3433397813352252\n"
     ]
    }
   ],
   "source": [
    "print(predict_toxicity(\"I have a christian friend\"))\n",
    "print(predict_toxicity(\"I have a muslim friend\"))\n",
    "print(predict_toxicity(\"I have a white friend\"))\n",
    "print(predict_toxicity(\"I have a black friend\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574031f5",
   "metadata": {},
   "source": [
    "Предсказания равномерны"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf761633-3e2b-4f00-83ce-e3501af24970",
   "metadata": {},
   "source": [
    "# Задание 9 \n",
    "Это может привести к нарушению справедливости модели, поскольку её предсказания будут зависеть не только от реальной токсичности комментария, но и от его тематики. Если определённые темы исторически или социально ассоциируются с негативными высказываниями в обучающей выборке (например, упоминание расы, религии или этнической принадлежности), модель может начать ошибочно считать такие слова маркерами токсичности, даже если контекст нейтральный. Это отражает предвзятость данных, на которых она обучалась, и может привести к дискриминационным предсказаниям."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f314c6-8b11-4585-a18e-cc2382bb99e4",
   "metadata": {},
   "source": [
    "# Задание 10\n",
    "- Сбор более сбалансированного датасета\n",
    "\n",
    "- Можно искусственно увеличить количество примеров нетоксичных комментариев на \"чувствительные\" темы \n",
    "\n",
    "- Фильтрация данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb50dcb",
   "metadata": {},
   "source": [
    "# Задание 11"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2dd42a",
   "metadata": {},
   "source": [
    "Этот фильтр перед тем как разбивать данные увеличит этичность"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "a516627d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4151673080399158\n",
      "0.42155025913898503\n",
      "0.3617148193271017\n",
      "0.3433397813352252\n"
     ]
    }
   ],
   "source": [
    "danger_themes = ['asian','atheist','black','buddhist','hindu','jewish','latino',\n",
    "                   'muslim','other_religion','white','christian','bisexual','heterosexual',\n",
    "                   'homosexual_gay_or_lesbian','intellectual_or_learning_disability','male',\n",
    "                   'other_disability','other_gender', 'other_race_or_ethnicity', 'other_sexual_orientation',\n",
    "                   'physical_disability','transgender', 'psychiatric_or_mental_illness']\n",
    "mask = (data[danger_themes] == 0).all(axis=1)\n",
    "data = data.loc[mask]\n",
    "\n",
    "comments = data[\"comment_text\"]\n",
    "target = (data[\"target\"]>0.7).astype(int)\n",
    "\n",
    "comm_train, comm_test, target_train, target_test = train_test_split(\n",
    "    comments, target, test_size=0.3, random_state=0\n",
    ")\n",
    "\n",
    "\n",
    "model = LogisticRegression(max_iter=2000)\n",
    "model.fit(comments_train_vec, target_train)\n",
    "\n",
    "print(predict_toxicity(\"I have a christian friend\"))\n",
    "print(predict_toxicity(\"I have a muslim friend\"))\n",
    "print(predict_toxicity(\"I have a white friend\"))\n",
    "print(predict_toxicity(\"I have a black friend\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9e1f99",
   "metadata": {},
   "source": [
    "Предсказания стали качественнее"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
